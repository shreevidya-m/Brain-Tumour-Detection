{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1d0wOrpV4SY"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "xRX_a9fVV5fX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a6f31e-f0f3-45d1-b9ca-bf4968ed2f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/Clean Data Set.zip\""
      ],
      "metadata": {
        "id": "86ho1njGV73z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daabf57b-8066-4769-c014-cf41cc6c703f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/gdrive/MyDrive/Clean Data Set.zip, /content/gdrive/MyDrive/Clean Data Set.zip.zip or /content/gdrive/MyDrive/Clean Data Set.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import shutil\n",
        "import glob"
      ],
      "metadata": {
        "id": "QmTZsXC2WD_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the number of images in the respective classes\n",
        "#0-Brain Tumour\n",
        "#1-Healthy Brain\n",
        "ROOT_DIR=\"/content/Clean Data Set\"\n",
        "number_of_images={}\n",
        "\n",
        "for dir in os.listdir(ROOT_DIR):\n",
        "  number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR,dir)))"
      ],
      "metadata": {
        "id": "uXEoI6SDWI4p",
        "outputId": "dbd0b416-981d-4225-8ef3-a75053c0797f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Clean Data Set'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5083d699e42f>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnumber_of_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mnumber_of_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Clean Data Set'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_images.items()"
      ],
      "metadata": {
        "id": "BjsIrZe6WLjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/Clean Data Set\")"
      ],
      "metadata": {
        "id": "aExKHOXUWNh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(\"/content/Clean Data Set\"))"
      ],
      "metadata": {
        "id": "MlMoEcOBWPWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA SPLIT\n",
        "\n",
        "*   50% for Train Data\n",
        "*   25% for Testing\n",
        "*   25% for Validation\n"
      ],
      "metadata": {
        "id": "bQASKK1D5wzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataFolder(p,split):\n",
        "  #we create a training folder\n",
        "\n",
        "  if not os.path.exists(\"./\"+p):\n",
        "    os.mkdir(\"./\"+p)\n",
        "\n",
        "  for dir in os.listdir(ROOT_DIR):\n",
        "    os.makedirs('./'+p+'/'+dir)\n",
        "    for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR,dir)),\n",
        "                                size=(math.floor(split*number_of_images[dir])-5),\n",
        "                                replace=False):\n",
        "     O=os.path.join(ROOT_DIR,dir,img)\n",
        "     D=os.path.join('./'+p,dir)\n",
        "     shutil.copy(O,D)\n",
        "     os.remove(O)\n",
        "  else:\n",
        "    print(f\"{p}Folder exists\")"
      ],
      "metadata": {
        "id": "rAUOQzAlWRef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataFolder(\"train\",0.5)"
      ],
      "metadata": {
        "id": "oLLb5bKgWZY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataFolder(\"val\",0.25)"
      ],
      "metadata": {
        "id": "na5AX4hUWc-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataFolder(\"test\",0.25)"
      ],
      "metadata": {
        "id": "6VcLiywVWgfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import  Conv2D,  MaxPool2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAvgPool2D\n",
        "from keras.models import  Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n"
      ],
      "metadata": {
        "id": "twG2DtJCWjv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Model\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3,3),activation='relu',input_shape=(224,224,3),padding='same' ))\n",
        "\n",
        "model.add(Conv2D(filters= 36, kernel_size= (3,3), activation= 'relu' ))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3),activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=64, activation= 'relu'))\n",
        "model.add(Dropout(rate= 0.25))\n",
        "model.add(Dense(units= 1,activation= 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "FxOZeEkkWnWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss= keras.losses.BinaryCrossentropy(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_fLGkixbW0Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessingImages1(path):\n",
        "  \"\"\"\n",
        "  input:Path\n",
        "  output:Pre processed image\n",
        "  \"\"\"\n",
        "  image_data=ImageDataGenerator(zoom_range=0.2,shear_range=0.2,rescale=1/225,horizontal_flip=True)# data Augmentation\n",
        "  image=image_data.flow_from_directory(directory=path,target_size=(224,224),batch_size=32,class_mode='binary')\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "q9c0ftDtW4Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/train\"\n",
        "train_data=preprocessingImages1(path)"
      ],
      "metadata": {
        "id": "OlWVCdVpXBRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessingImages2(path):\n",
        "  \"\"\"\n",
        "  input:Path\n",
        "  output:Pre processed image\n",
        "  \"\"\"\n",
        "  image_data=ImageDataGenerator(rescale=1/225)\n",
        "  image=image_data.flow_from_directory(directory=path,target_size=(224,224),batch_size=32,class_mode='binary')\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "jXEv1op8XGtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/test\"\n",
        "test_data=preprocessingImages2(path)"
      ],
      "metadata": {
        "id": "xXlABcTnXJiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/val\"\n",
        "val_data=preprocessingImages2(path)"
      ],
      "metadata": {
        "id": "TSk8lG0zchOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Early stopping and model check point\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "#early stopping\n",
        "\n",
        "es=EarlyStopping(monitor='val_accuracy',min_delta=0.01,patience=10,verbose=1,mode='auto')\n",
        "\n",
        "#model check point\n",
        "mc=ModelCheckpoint(monitor='val_accuracy',filepath=\"./bestmodel.h5\",save_best_only=True ,verbose=1,mode='auto')\n",
        "cd=[es,mc]"
      ],
      "metadata": {
        "id": "K6NBeR-7XL5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hs = model.fit(train_data,\n",
        "               steps_per_epoch= 8,\n",
        "               epochs= 30,\n",
        "               verbose= 1,\n",
        "               validation_data=val_data,\n",
        "               validation_steps= 16,\n",
        "               callbacks= cd)"
      ],
      "metadata": {
        "id": "5hkSgp2yYYgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Graphical Interpretation\n",
        "\n",
        "h=hs.history\n",
        "h.keys()"
      ],
      "metadata": {
        "id": "NsM3pBqRa4zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(h['accuracy'],c='red')\n",
        "plt.plot(h['val_accuracy'],c='blue')\n",
        "plt.title(\"acc\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BmZdon-7a5v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(h['loss'],c='red')\n",
        "plt.plot(h['val_loss'])\n",
        "plt.title('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rNNV71YRoib7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model accuracy\n",
        "from keras.models import load_model\n",
        "model=load_model(\"/content/bestmodel.h5\")"
      ],
      "metadata": {
        "id": "CPhIHyr2owMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=model.evaluate_generator(test_data)[1]\n",
        "print(f\"the accuracy of our model is {acc*100} %\")"
      ],
      "metadata": {
        "id": "k-aMxtx5o0hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array"
      ],
      "metadata": {
        "id": "95QOFw_VKVcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = '/content/train/no tumour/no_tumour101.jpg'\n",
        "img=load_img(path,target_size=(224,224))\n",
        "input_arr=img_to_array(img)/255\n",
        "\n",
        "plt.imshow(input_arr)\n",
        "plt.show()\n",
        "\n",
        "input_arr.shape\n",
        "\n",
        "input_arr=np.expand_dims(input_arr,axis=0)\n",
        "y_pred_LogisticRegression=model.predict(input_arr)\n",
        "\n",
        "\n",
        "if y_pred_LogisticRegression==1:\n",
        "  print(\"the MRI is having a Tumour\")\n",
        "else:\n",
        "  print(\"the MRI is having no Tumour\")"
      ],
      "metadata": {
        "id": "ncVpPKW_pfze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = '/content/train/tumour/tumour101.jpg'\n",
        "\n",
        "img_array = np.array(img)\n",
        "img_array.shape\n",
        "\n",
        "img_array = img_array.shape(1,150,150,3)\n",
        "img_array.shape\n",
        "\n",
        "img = load_img('/content/train/tumour/tumour101.jpg')\n",
        "plt.imshow(img,interpolation='nearest')\n",
        "plt.show()\n",
        "\n",
        "a=model.predict(img_array)\n",
        "indices = a.argmax()\n",
        "indices\n"
      ],
      "metadata": {
        "id": "mlqpRBunW8vg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}